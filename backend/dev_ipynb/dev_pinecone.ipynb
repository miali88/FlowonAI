{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def initialize_pinecone():\n",
    "    \"\"\"Initialize Pinecone client\"\"\"\n",
    "    return Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "\n",
    "def get_or_create_index(pc, index_name=\"quickstart\", dimension=1024):\n",
    "    \"\"\"Get existing index or create if it doesn't exist\"\"\"\n",
    "    # Check if index already exists\n",
    "    existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "    \n",
    "    if index_name not in existing_indexes:\n",
    "        print(f\"Creating new index: {index_name}\")\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=dimension,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Wait for the index to be ready\n",
    "        while not pc.describe_index(index_name).status['ready']:\n",
    "            time.sleep(1)\n",
    "    else:\n",
    "        print(f\"Using existing index: {index_name}\")\n",
    "    \n",
    "    return pc.Index(index_name)\n",
    "\n",
    "\n",
    "def store_embeddings(data, index, namespace=\"ns1\", model=\"multilingual-e5-large\", batch_size=100):\n",
    "    \"\"\"Create embeddings and store them in Pinecone with batching\"\"\"\n",
    "    pc = initialize_pinecone()\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i + batch_size]\n",
    "        \n",
    "        # Generate embeddings for batch\n",
    "        embeddings = pc.inference.embed(\n",
    "            model=model,\n",
    "            inputs=[d['text'] for d in batch],\n",
    "            parameters={\"input_type\": \"passage\", \"truncate\": \"END\"}\n",
    "        )\n",
    "        \n",
    "        # Prepare vectors\n",
    "        vectors = [\n",
    "            {\n",
    "                \"id\": d['id'],\n",
    "                \"values\": e['values'],\n",
    "                \"metadata\": {'text': d['text']}\n",
    "            }\n",
    "            for d, e in zip(batch, embeddings)\n",
    "        ]\n",
    "        \n",
    "        # Upload batch to Pinecone\n",
    "        index.upsert(vectors=vectors, namespace=namespace)\n",
    "        \n",
    "        print(f\"Processed batch {i//batch_size + 1}\")\n",
    "    \n",
    "    return index.describe_index_stats()\n",
    "\n",
    "\n",
    "def query_embeddings(query_text, index, namespace=\"ns1\", top_k=10, model=\"multilingual-e5-large\"):\n",
    "    \"\"\"Query the Pinecone index\"\"\"\n",
    "    pc = initialize_pinecone()\n",
    "    \n",
    "    # Generate embedding for query\n",
    "    embedding = pc.inference.embed(\n",
    "        model=model,\n",
    "        inputs=[query_text],\n",
    "        parameters={\"input_type\": \"query\"}\n",
    "    )\n",
    "    \n",
    "    # Query the index\n",
    "    results = index.query(\n",
    "        namespace=namespace,\n",
    "        vector=embedding[0].values,\n",
    "        top_k=top_k,\n",
    "        include_values=False,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Pinecone (do this once)\n",
    "pc = initialize_pinecone()\n",
    "\n",
    "# Get or create index (do this once per application startup)\n",
    "index = get_or_create_index(pc, \"web_data\", dimension=1024)\n",
    "\n",
    "# You can now use this index multiple times for different operations\n",
    "\n",
    "# Example: Adding new data\n",
    "new_data = [\n",
    "    {\"id\": \"doc1\", \"text\": \"Some new document...\"},\n",
    "    {\"id\": \"doc2\", \"text\": \"Another document...\"}\n",
    "]\n",
    "store_embeddings(new_data, index)\n",
    "\n",
    "# Example: Querying\n",
    "results = query_embeddings(\"your query\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.db.supabase_services import supabase_client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "supabase = supabase_client()\n",
    "\n",
    "results = supabase.table(\"user_web_data\").select(\"*\").eq(\"root_url\", \"https://piqnic.com\").execute()\n",
    "results.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the data as you did\n",
    "supabase = supabase_client()\n",
    "results = supabase.table(\"user_web_data\").select(\"*\").eq(\"root_url\", \"https://piqnic.com\").execute()\n",
    "\n",
    "# Define the user_id you want to add\n",
    "new_user_id = \"user_2mmXezcGmjZCf88gT2v2waCBsXv\"  # Replace with the actual user_id you want to set\n",
    "\n",
    "# Update all matching rows\n",
    "for row in results.data:\n",
    "    supabase.table(\"user_web_data\")\\\n",
    "           .update({\"user_id\": new_user_id})\\\n",
    "           .eq(\"id\", row[\"id\"])\\\n",
    "           .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "similarity_search...\n",
      "\n",
      "\n",
      " data_source: {'web': ['https://piqnic.com/']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error querying table user_text_files: 'text_files'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of results: 0\n",
      "\n",
      "\n",
      "\n",
      " all_results: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from services.chat.chat import similarity_search\n",
    "\n",
    "results = await similarity_search(query = \"What services do you offer?\", data_source = {\"web\": [\"https://piqnic.com/\"]}, user_id =  \"user_2mmXezcGmjZCf88gT2v2waCBsXv\")\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
