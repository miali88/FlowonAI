{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def initialize_pinecone():\n",
    "    \"\"\"Initialize Pinecone client\"\"\"\n",
    "    return Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "\n",
    "def get_or_create_index(pc, index_name=\"quickstart\", dimension=1024):\n",
    "    \"\"\"Get existing index or create if it doesn't exist\"\"\"\n",
    "    # Check if index already exists\n",
    "    existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "    \n",
    "    if index_name not in existing_indexes:\n",
    "        print(f\"Creating new index: {index_name}\")\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=dimension,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Wait for the index to be ready\n",
    "        while not pc.describe_index(index_name).status['ready']:\n",
    "            time.sleep(1)\n",
    "    else:\n",
    "        print(f\"Using existing index: {index_name}\")\n",
    "    \n",
    "    return pc.Index(index_name)\n",
    "\n",
    "\n",
    "def store_embeddings(data, index, namespace=\"ns1\", model=\"multilingual-e5-large\", batch_size=100):\n",
    "    \"\"\"Create embeddings and store them in Pinecone with batching\"\"\"\n",
    "    pc = initialize_pinecone()\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i + batch_size]\n",
    "        \n",
    "        # Generate embeddings for batch\n",
    "        embeddings = pc.inference.embed(\n",
    "            model=model,\n",
    "            inputs=[d['text'] for d in batch],\n",
    "            parameters={\"input_type\": \"passage\", \"truncate\": \"END\"}\n",
    "        )\n",
    "        \n",
    "        # Prepare vectors\n",
    "        vectors = [\n",
    "            {\n",
    "                \"id\": d['id'],\n",
    "                \"values\": e['values'],\n",
    "                \"metadata\": {'text': d['text']}\n",
    "            }\n",
    "            for d, e in zip(batch, embeddings)\n",
    "        ]\n",
    "        \n",
    "        # Upload batch to Pinecone\n",
    "        index.upsert(vectors=vectors, namespace=namespace)\n",
    "        \n",
    "        print(f\"Processed batch {i//batch_size + 1}\")\n",
    "    \n",
    "    return index.describe_index_stats()\n",
    "\n",
    "\n",
    "def query_embeddings(query_text, index, namespace=\"ns1\", top_k=10, model=\"multilingual-e5-large\"):\n",
    "    \"\"\"Query the Pinecone index\"\"\"\n",
    "    pc = initialize_pinecone()\n",
    "    \n",
    "    # Generate embedding for query\n",
    "    embedding = pc.inference.embed(\n",
    "        model=model,\n",
    "        inputs=[query_text],\n",
    "        parameters={\"input_type\": \"query\"}\n",
    "    )\n",
    "    \n",
    "    # Query the index\n",
    "    results = index.query(\n",
    "        namespace=namespace,\n",
    "        vector=embedding[0].values,\n",
    "        top_k=top_k,\n",
    "        include_values=False,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "\n",
    "index_name = \"quickstart\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1024, # Replace with your model dimensions\n",
    "    metric=\"cosine\", # Replace with your model metric\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ")\n",
    "\n",
    "data = [\n",
    "    {\"id\": \"vec1\", \"text\": \"Apple is a popular fruit known for its sweetness and crisp texture.\"},\n",
    "    {\"id\": \"vec2\", \"text\": \"The tech company Apple is known for its innovative products like the iPhone.\"},\n",
    "    {\"id\": \"vec3\", \"text\": \"Many people enjoy eating apples as a healthy snack.\"},\n",
    "    {\"id\": \"vec4\", \"text\": \"Apple Inc. has revolutionized the tech industry with its sleek designs and user-friendly interfaces.\"},\n",
    "    {\"id\": \"vec5\", \"text\": \"An apple a day keeps the doctor away, as the saying goes.\"},\n",
    "    {\"id\": \"vec6\", \"text\": \"Apple Computer Company was founded on April 1, 1976, by Steve Jobs, Steve Wozniak, and Ronald Wayne as a partnership.\"}\n",
    "]\n",
    "\n",
    "embeddings = pc.inference.embed(\n",
    "    model=\"multilingual-e5-large\",\n",
    "    inputs=[d['text'] for d in data],\n",
    "    parameters={\"input_type\": \"passage\", \"truncate\": \"END\"}\n",
    ")\n",
    "print(embeddings[0])\n",
    "\n",
    "\n",
    "# Wait for the index to be ready\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "vectors = []\n",
    "for d, e in zip(data, embeddings):\n",
    "    vectors.append({\n",
    "        \"id\": d['id'],\n",
    "        \"values\": e['values'],\n",
    "        \"metadata\": {'text': d['text']}\n",
    "    })\n",
    "\n",
    "index.upsert(\n",
    "    vectors=vectors,\n",
    "    namespace=\"ns1\"\n",
    ")\n",
    "\n",
    "print(index.describe_index_stats())\n",
    "\n",
    "\n",
    "query = \"Tell me about the tech company known as Apple.\"\n",
    "\n",
    "embedding = pc.inference.embed(\n",
    "    model=\"multilingual-e5-large\",\n",
    "    inputs=[query],\n",
    "    parameters={\n",
    "        \"input_type\": \"query\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "results = index.query(\n",
    "    namespace=\"ns1\",\n",
    "    vector=embedding[0].values,\n",
    "    top_k=3,\n",
    "    include_values=False,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
