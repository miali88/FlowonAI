{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat.chat import similarity_search\n",
    "from services.db.supabase_services import get_supabase\n",
    "\n",
    "supabase = await get_supabase()\n",
    "\n",
    "onboarding_table = await supabase.table(\"users\").select(\"*\").eq(\"id\", \"user_2rx2BrhfVU1jkrvxUyZGllu6H4m\").execute()\n",
    "onboarding_table = onboarding_table.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_steps = [\n",
    "    {\"step\": \"CREATE_AGENT\", \"isCompleted\": False},\n",
    "    {\"step\": \"KNOWLEDGE_BASE_ADD\", \"isCompleted\": True},\n",
    "    {\"step\": \"FIRST_AGENT_INTERACTION\", \"isCompleted\": True},\n",
    "    {\"step\": \"INTEGRATE_FIRST_APP\", \"isCompleted\": False},\n",
    "]\n",
    "\n",
    "# Check if all onboarding steps are completed\n",
    "all_steps_completed = all(\n",
    "    onboarding_table[step[\"step\"].lower()]\n",
    "    for step in onboarding_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'create_agent': True,\n",
       " 'knowledge_base_add': True,\n",
       " 'first_agent_interaction': True,\n",
       " 'integrate_first_app': True}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onboarding_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user_2rx2BrhfVU1jkrvxUyZGllu6H4m'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m content  \u001b[38;5;66;03m# Returns a list of JSON-like dictionaries\u001b[39;00m\n\u001b[1;32m     23\u001b[0m listings \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlistings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m process_csv(listings)\n",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36mprocess_csv\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_csv\u001b[39m(file: UploadFile) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m      9\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing CSV file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     csv_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m()\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Decode bytes to string and create a string IO object\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     csv_string \u001b[38;5;241m=\u001b[39m csv_content\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import io\n",
    "from fastapi import UploadFile\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "async def process_csv(file: UploadFile) -> list[dict]:\n",
    "    logger.info(\"Processing CSV file\")\n",
    "    csv_content = await file.read()\n",
    "    \n",
    "    # Decode bytes to string and create a string IO object\n",
    "    csv_string = csv_content.decode('utf-8')\n",
    "    csv_file = io.StringIO(csv_string)\n",
    "    \n",
    "    # Read CSV file into a list of dictionaries\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    content = [row for row in csv_reader]  # Each row is now a dictionary\n",
    "    \n",
    "    logger.info(\"CSV processed successfully\")\n",
    "    return content  # Returns a list of JSON-like dictionaries\n",
    "\n",
    "listings = 'listings.csv'\n",
    "\n",
    "await process_csv(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Price   ': '875000', 'Bedrooms ': '2', 'Bathrooms ': '2', 'Receptions ': '1', 'Square_Feet ': '            ', 'Address            ': 'Ifield Road        ', 'City': 'London   ', 'Postcode': 'SW10   ', 'Tenure': 'Leasehold         ', 'Features                            ': \"Barnard Marcus - Earl's Court       \", 'Description  1': 'Good Transport Links, No Chain, Reduced ', 'Description 2': 'A delightful two double bedroom apartment situated on this highly desirable tree lined street ', 'Property_Type                                                                                   ': 'Apartment ', 'New_Build': 'No'}, {'Price   ': '695000', 'Bedrooms ': '2', 'Bathrooms ': '2', 'Receptions ': '1', 'Square_Feet ': '793', 'Address            ': \"World's End Estate \", 'City': 'London   ', 'Postcode': 'SW10   ', 'Tenure': 'Leasehold         ', 'Features                            ': 'Martin & Co - Chelsea Riverside     ', 'Description  1': 'Balcony, Panoramic Views                ', 'Description 2': 'Spectacular 800 sq ft apartment with balcony and arguably the best view in Chelsea            ', 'Property_Type                                                                                   ': 'Apartment ', 'New_Build': 'No'}, {'Price   ': '500000', 'Bedrooms ': '1', 'Bathrooms ': '1', 'Receptions ': '1', 'Square_Feet ': '411', 'Address            ': 'Finborough Road    ', 'City': 'London   ', 'Postcode': 'SW10   ', 'Tenure': 'Leasehold         ', 'Features                            ': 'Martin & Co - Chelsea               ', 'Description  1': 'Terrace, Dual Aspect                    ', 'Description 2': 'Charming 1 bedroom apartment with terrace in convenient Chelsea location                      ', 'Property_Type                                                                                   ': 'Apartment ', 'New_Build': 'No'}, {'Price   ': '4853000', 'Bedrooms ': '4', 'Bathrooms ': '4', 'Receptions ': '1', 'Square_Feet ': '2166', 'Address            ': 'Chelsea Waterfront ', 'City': 'London   ', 'Postcode': 'SW10   ', 'Tenure': 'Leasehold         ', 'Features                            ': 'Allie Home Estate & Lettings Agency ', 'Description  1': 'River Views, Concierge                  ', 'Description 2': 'Ultra-luxurious apartment with stunning River Thames views                                    ', 'Property_Type                                                                                   ': 'Apartment ', 'New_Build': 'Yes'}, {'Price   ': '2411000', 'Bedrooms ': '2', 'Bathrooms ': '2', 'Receptions ': '1', 'Square_Feet ': '1032', 'Address            ': 'Chelsea Waterfront ', 'City': 'London   ', 'Postcode': 'SW10   ', 'Tenure': 'Leasehold         ', 'Features                            ': 'Allie Home Estate & Lettings Agency ', 'Description  1': 'River Views, Smart Home                 ', 'Description 2': 'Luxurious 2-bed apartment with high-end finishes                                              ', 'Property_Type                                                                                   ': 'Apartment ', 'New_Build': 'Yes'}, {'Price   ': '2008000', 'Bedrooms ': '3', 'Bathrooms ': '3', 'Receptions ': '1', 'Square_Feet ': '1309', 'Address            ': 'Chelsea Waterfront ', 'City': 'London   ', 'Postcode': 'SW10   ', 'Tenure': 'Leasehold         ', 'Features                            ': 'Allie Home Estate & Lettings Agency ', 'Description  1': 'Open Plan, Luxury Finishes              ', 'Description 2': '2+1 bed apartment with open-plan kitchen                                                      ', 'Property_Type                                                                                   ': 'Apartment ', 'New_Build': 'Yes'}, {'Price   ': '2350000', 'Bedrooms ': '3', 'Bathrooms ': '2', 'Receptions ': '1', 'Square_Feet ': '1421', 'Address            ': 'Harbour Avenue     ', 'City': 'London   ', 'Postcode': 'SW10   ', 'Tenure': 'Leasehold         ', 'Features                            ': 'Dexters - New Homes South           ', 'Description  1': 'Chelsea Harbour, West Facing            ', 'Description 2': 'Luxury three bedroom apartment in sought after Chelsea Harbour                                ', 'Property_Type                                                                                   ': 'Apartment ', 'New_Build': 'Yes'}, {'Price   ': '1500000', 'Bedrooms ': '2', 'Bathrooms ': '2', 'Receptions ': '1', 'Square_Feet ': '990', 'Address            ': 'Harbour Avenue     ', 'City': 'London   ', 'Postcode': 'SW10   ', 'Tenure': 'Leasehold         ', 'Features                            ': 'Dexters - New Homes South           ', 'Description  1': 'Contemporary Design                     ', 'Description 2': 'West facing apartment on 3rd floor                                                            ', 'Property_Type                                                                                   ': 'Apartment ', 'New_Build': 'Yes'}, {'Price   ': '2150000', 'Bedrooms ': '2', 'Bathrooms ': '2', 'Receptions ': '1', 'Square_Feet ': '1281', 'Address            ': 'Harbour Avenue     ', 'City': 'London   ', 'Postcode': 'SW10   ', 'Tenure': 'Leasehold         ', 'Features                            ': 'Dexters - New Homes South           ', 'Description  1': 'Luxury Finish, Fourth Floor             ', 'Description 2': 'Two bedroom apartment in Lighterman Towers                                                    ', 'Property_Type                                                                                   ': 'Apartment ', 'New_Build': 'Yes'}, {'Price   ': '875000', 'Bedrooms ': '2', 'Bathrooms ': '1', 'Receptions ': '1', 'Square_Feet ': '537', 'Address            ': 'Park Walk          ', 'City': 'London   ', 'Postcode': 'SW10   ', 'Tenure': 'Share of Freehold ', 'Features                            ': 'Hamptons - Chelsea Sales            ', 'Description  1': 'Period Features                         ', 'Description 2': 'Well presented two double bedroom in mansion block                                            ', 'Property_Type                                                                                   ': 'Apartment ', 'New_Build': 'No'}, {'Price   ': '2000000', 'Bedrooms ': '2', 'Bathrooms ': '2', 'Receptions ': '1', 'Square_Feet ': '            ', 'Address            ': 'Fulham Road        ', 'City': 'London   ', 'Postcode': 'SW10   ', 'Tenure': 'Leasehold         ', 'Features                            ': 'Aspire - Fulham South               ', 'Description  1': 'Split Level, Modern Design              ', 'Description 2': 'Stunning split level apartment in heart of Chelsea                                            ', 'Property_Type                                                                                   ': 'Apartment ', 'New_Build': 'No'}]\n"
     ]
    }
   ],
   "source": [
    "from fastapi import UploadFile\n",
    "import aiofiles\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import io\n",
    "\n",
    "async def create_upload_file(filepath: str) -> UploadFile:\n",
    "    path = Path(filepath)\n",
    "    async with aiofiles.open(path, 'rb') as f:\n",
    "        content = await f.read()\n",
    "    \n",
    "    return UploadFile(\n",
    "        filename=path.name,\n",
    "        file=io.BytesIO(content)\n",
    "    )\n",
    "\n",
    "async def main():\n",
    "    # Replace with your CSV file path\n",
    "    file_path = \"listings.csv\"\n",
    "    upload_file = await create_upload_file(file_path)\n",
    "    result = await process_csv(upload_file)\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "# Run in Jupyter notebook\n",
    "data = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Price   ': '875000',\n",
       "  'Bedrooms ': '2',\n",
       "  'Bathrooms ': '2',\n",
       "  'Receptions ': '1',\n",
       "  'Square_Feet ': '            ',\n",
       "  'Address            ': 'Ifield Road        ',\n",
       "  'City': 'London   ',\n",
       "  'Postcode': 'SW10   ',\n",
       "  'Tenure': 'Leasehold         ',\n",
       "  'Features                            ': \"Barnard Marcus - Earl's Court       \",\n",
       "  'Description  1': 'Good Transport Links, No Chain, Reduced ',\n",
       "  'Description 2': 'A delightful two double bedroom apartment situated on this highly desirable tree lined street ',\n",
       "  'Property_Type                                                                                   ': 'Apartment ',\n",
       "  'New_Build': 'No'},\n",
       " {'Price   ': '695000',\n",
       "  'Bedrooms ': '2',\n",
       "  'Bathrooms ': '2',\n",
       "  'Receptions ': '1',\n",
       "  'Square_Feet ': '793',\n",
       "  'Address            ': \"World's End Estate \",\n",
       "  'City': 'London   ',\n",
       "  'Postcode': 'SW10   ',\n",
       "  'Tenure': 'Leasehold         ',\n",
       "  'Features                            ': 'Martin & Co - Chelsea Riverside     ',\n",
       "  'Description  1': 'Balcony, Panoramic Views                ',\n",
       "  'Description 2': 'Spectacular 800 sq ft apartment with balcony and arguably the best view in Chelsea            ',\n",
       "  'Property_Type                                                                                   ': 'Apartment ',\n",
       "  'New_Build': 'No'},\n",
       " {'Price   ': '500000',\n",
       "  'Bedrooms ': '1',\n",
       "  'Bathrooms ': '1',\n",
       "  'Receptions ': '1',\n",
       "  'Square_Feet ': '411',\n",
       "  'Address            ': 'Finborough Road    ',\n",
       "  'City': 'London   ',\n",
       "  'Postcode': 'SW10   ',\n",
       "  'Tenure': 'Leasehold         ',\n",
       "  'Features                            ': 'Martin & Co - Chelsea               ',\n",
       "  'Description  1': 'Terrace, Dual Aspect                    ',\n",
       "  'Description 2': 'Charming 1 bedroom apartment with terrace in convenient Chelsea location                      ',\n",
       "  'Property_Type                                                                                   ': 'Apartment ',\n",
       "  'New_Build': 'No'},\n",
       " {'Price   ': '4853000',\n",
       "  'Bedrooms ': '4',\n",
       "  'Bathrooms ': '4',\n",
       "  'Receptions ': '1',\n",
       "  'Square_Feet ': '2166',\n",
       "  'Address            ': 'Chelsea Waterfront ',\n",
       "  'City': 'London   ',\n",
       "  'Postcode': 'SW10   ',\n",
       "  'Tenure': 'Leasehold         ',\n",
       "  'Features                            ': 'Allie Home Estate & Lettings Agency ',\n",
       "  'Description  1': 'River Views, Concierge                  ',\n",
       "  'Description 2': 'Ultra-luxurious apartment with stunning River Thames views                                    ',\n",
       "  'Property_Type                                                                                   ': 'Apartment ',\n",
       "  'New_Build': 'Yes'},\n",
       " {'Price   ': '2411000',\n",
       "  'Bedrooms ': '2',\n",
       "  'Bathrooms ': '2',\n",
       "  'Receptions ': '1',\n",
       "  'Square_Feet ': '1032',\n",
       "  'Address            ': 'Chelsea Waterfront ',\n",
       "  'City': 'London   ',\n",
       "  'Postcode': 'SW10   ',\n",
       "  'Tenure': 'Leasehold         ',\n",
       "  'Features                            ': 'Allie Home Estate & Lettings Agency ',\n",
       "  'Description  1': 'River Views, Smart Home                 ',\n",
       "  'Description 2': 'Luxurious 2-bed apartment with high-end finishes                                              ',\n",
       "  'Property_Type                                                                                   ': 'Apartment ',\n",
       "  'New_Build': 'Yes'},\n",
       " {'Price   ': '2008000',\n",
       "  'Bedrooms ': '3',\n",
       "  'Bathrooms ': '3',\n",
       "  'Receptions ': '1',\n",
       "  'Square_Feet ': '1309',\n",
       "  'Address            ': 'Chelsea Waterfront ',\n",
       "  'City': 'London   ',\n",
       "  'Postcode': 'SW10   ',\n",
       "  'Tenure': 'Leasehold         ',\n",
       "  'Features                            ': 'Allie Home Estate & Lettings Agency ',\n",
       "  'Description  1': 'Open Plan, Luxury Finishes              ',\n",
       "  'Description 2': '2+1 bed apartment with open-plan kitchen                                                      ',\n",
       "  'Property_Type                                                                                   ': 'Apartment ',\n",
       "  'New_Build': 'Yes'},\n",
       " {'Price   ': '2350000',\n",
       "  'Bedrooms ': '3',\n",
       "  'Bathrooms ': '2',\n",
       "  'Receptions ': '1',\n",
       "  'Square_Feet ': '1421',\n",
       "  'Address            ': 'Harbour Avenue     ',\n",
       "  'City': 'London   ',\n",
       "  'Postcode': 'SW10   ',\n",
       "  'Tenure': 'Leasehold         ',\n",
       "  'Features                            ': 'Dexters - New Homes South           ',\n",
       "  'Description  1': 'Chelsea Harbour, West Facing            ',\n",
       "  'Description 2': 'Luxury three bedroom apartment in sought after Chelsea Harbour                                ',\n",
       "  'Property_Type                                                                                   ': 'Apartment ',\n",
       "  'New_Build': 'Yes'},\n",
       " {'Price   ': '1500000',\n",
       "  'Bedrooms ': '2',\n",
       "  'Bathrooms ': '2',\n",
       "  'Receptions ': '1',\n",
       "  'Square_Feet ': '990',\n",
       "  'Address            ': 'Harbour Avenue     ',\n",
       "  'City': 'London   ',\n",
       "  'Postcode': 'SW10   ',\n",
       "  'Tenure': 'Leasehold         ',\n",
       "  'Features                            ': 'Dexters - New Homes South           ',\n",
       "  'Description  1': 'Contemporary Design                     ',\n",
       "  'Description 2': 'West facing apartment on 3rd floor                                                            ',\n",
       "  'Property_Type                                                                                   ': 'Apartment ',\n",
       "  'New_Build': 'Yes'},\n",
       " {'Price   ': '2150000',\n",
       "  'Bedrooms ': '2',\n",
       "  'Bathrooms ': '2',\n",
       "  'Receptions ': '1',\n",
       "  'Square_Feet ': '1281',\n",
       "  'Address            ': 'Harbour Avenue     ',\n",
       "  'City': 'London   ',\n",
       "  'Postcode': 'SW10   ',\n",
       "  'Tenure': 'Leasehold         ',\n",
       "  'Features                            ': 'Dexters - New Homes South           ',\n",
       "  'Description  1': 'Luxury Finish, Fourth Floor             ',\n",
       "  'Description 2': 'Two bedroom apartment in Lighterman Towers                                                    ',\n",
       "  'Property_Type                                                                                   ': 'Apartment ',\n",
       "  'New_Build': 'Yes'},\n",
       " {'Price   ': '875000',\n",
       "  'Bedrooms ': '2',\n",
       "  'Bathrooms ': '1',\n",
       "  'Receptions ': '1',\n",
       "  'Square_Feet ': '537',\n",
       "  'Address            ': 'Park Walk          ',\n",
       "  'City': 'London   ',\n",
       "  'Postcode': 'SW10   ',\n",
       "  'Tenure': 'Share of Freehold ',\n",
       "  'Features                            ': 'Hamptons - Chelsea Sales            ',\n",
       "  'Description  1': 'Period Features                         ',\n",
       "  'Description 2': 'Well presented two double bedroom in mansion block                                            ',\n",
       "  'Property_Type                                                                                   ': 'Apartment ',\n",
       "  'New_Build': 'No'},\n",
       " {'Price   ': '2000000',\n",
       "  'Bedrooms ': '2',\n",
       "  'Bathrooms ': '2',\n",
       "  'Receptions ': '1',\n",
       "  'Square_Feet ': '            ',\n",
       "  'Address            ': 'Fulham Road        ',\n",
       "  'City': 'London   ',\n",
       "  'Postcode': 'SW10   ',\n",
       "  'Tenure': 'Leasehold         ',\n",
       "  'Features                            ': 'Aspire - Fulham South               ',\n",
       "  'Description  1': 'Split Level, Modern Design              ',\n",
       "  'Description 2': 'Stunning split level apartment in heart of Chelsea                                            ',\n",
       "  'Property_Type                                                                                   ': 'Apartment ',\n",
       "  'New_Build': 'No'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:8000/api/v1/stripe/create-payment-link\"\n",
    "payload = {\n",
    "    \"product_id\": \"prod_RcfvpRgzSUvVXj\",\n",
    "    \"quantity\": 1,\n",
    "    \"unit_amount\": 249,\n",
    "    \"currency\": \"usd\"  # optional, defaults to \"usd\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.twilio import get_available_numbers\n",
    "from typing import Dict, Any\n",
    "from services.twilio import client\n",
    "\n",
    "country_code = \"GB\"\n",
    "\n",
    "#get_available_numbers(\"HK\")\n",
    "# Try to list up to 5 numbers of each type\n",
    "    # Map our internal types to Twilio's pricing types\n",
    "number_type_mapping = {\n",
    "    'local': 'local',\n",
    "    'toll_free': 'toll free',\n",
    "    'mobile': 'mobile',\n",
    "    'national': 'national'\n",
    "}\n",
    "number_types = list(number_type_mapping.keys())\n",
    "available_numbers: Dict[str, Dict] = {}\n",
    "monthly_cost: Dict[str, float] = {}\n",
    "\n",
    "for number_type in number_types:\n",
    "    try:\n",
    "        print(f\"Getting {number_type} numbers for {country_code}\")\n",
    "        # Try to list up to 5 numbers of each type\n",
    "        numbers = getattr(client.available_phone_numbers(country_code), number_type).list(limit=5)\n",
    "        numbers_list = [number.phone_number for number in numbers]\n",
    "\n",
    "        country_pricing = client.pricing.v1.phone_numbers.countries(country_code).fetch()\n",
    "        country_pricing = country_pricing.phone_number_prices\n",
    "\n",
    "        print(f\"Got {len(numbers_list)} {number_type}, numbers {numbers_list}\")\n",
    "        # print(f\"Pricing: {country_pricing}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting {number_type} numbers for {country_code}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "country_pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purchase_phone_number(phone_number: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Purchase a specific phone number from Twilio\n",
    "    \n",
    "    Args:\n",
    "        phone_number (str): The phone number to purchase in E.164 format (e.g., '+1234567890')\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, Any]: Dictionary containing the purchased number details\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If the purchase fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        purchased_number = client.incoming_phone_numbers.create(\n",
    "            phone_number=phone_number\n",
    "        )\n",
    "        return {\n",
    "            'phone_number': purchased_number.phone_number,\n",
    "            'sid': purchased_number.sid,\n",
    "            'friendly_name': purchased_number.friendly_name,\n",
    "            'capabilities': {\n",
    "                'voice': purchased_number.capabilities.get('voice', False),\n",
    "                'sms': purchased_number.capabilities.get('sms', False),\n",
    "                'mms': purchased_number.capabilities.get('mms', False)\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to purchase number: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "response = purchase_phone_number(\"+13614281772\")\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pricing_for_numbers(client, destination_numbers, origination_number=None):\n",
    "    results = []\n",
    "    for number in destination_numbers:\n",
    "        try:\n",
    "            pricing = client.pricing.v2.numbers(number).fetch(\n",
    "                origination_number=origination_number\n",
    "            )\n",
    "            results.append({\n",
    "                'number': number,\n",
    "                'country': pricing.country,\n",
    "                'price_unit': pricing.price_unit,\n",
    "                'terminating_prefix_prices': pricing.terminating_prefix_prices,\n",
    "                'originating_call_price': pricing.originating_call_price\n",
    "            })\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                'number': number,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    return results\n",
    "\n",
    "# Usage\n",
    "pricing_results = get_pricing_for_numbers(client, numbers['local'], '+0987654321')\n",
    "\n",
    "pricing_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.knowledge_base.web_scrape import scrape_url\n",
    "\n",
    "urls = [\"https://api.slack.com/methods\",\n",
    "\"https://api.slack.com/methods/conversations.replies\",\n",
    "\"https://api.slack.com/methods/bots.info\"]\n",
    "\n",
    "# \"https://api.slack.com/methods/dnd.teamInfo\",\n",
    "# \"https://api.slack.com/methods/workflows.stepFailed\",\n",
    "# \"https://api.slack.com/methods/search.all\",\n",
    "# \"https://api.slack.com/methods/rtm.start\",\n",
    "# \"https://api.slack.com/methods/functions.completeError\",\n",
    "# \"https://api.slack.com/methods/chat.deleteScheduledMessage\",\n",
    "# \"https://api.slack.com/methods/files.getUploadURLExternal\",\n",
    "# \"https://api.slack.com/methods/reminders.list\",\n",
    "# \"https://api.slack.com/methods/usergroups.update\",\n",
    "# \"https://api.slack.com/methods/users.setActive\",\n",
    "# \"https://api.slack.com/methods/stars.remove\",\n",
    "# \"https://api.slack.com/methods/reactions.remove\",\n",
    "# \"https://api.slack.com/methods/bookmarks.remove\",\n",
    "# \"https://api.slack.com/methods/views.publish\",\n",
    "# \"https://api.slack.com/methods/emoji.list\",\n",
    "# \"https://api.slack.com/methods/team.info\",\n",
    "# \"https://api.slack.com/methods/apps.uninstall\",\n",
    "# \"https://api.slack.com/methods/migration.exchange\",\n",
    "# \"https://api.slack.com/methods/dialog.open\",\n",
    "# \"https://api.slack.com/methods/calls.info\",\n",
    "# \"https://api.slack.com/methods/oauth.access\",\n",
    "# \"https://api.slack.com/methods/pins.list\",\n",
    "# \"https://api.slack.com/methods/apps.datastore.bulkGet\",\n",
    "# \"https://api.slack.com/methods/admin.conversations.delete\",\n",
    "# \"https://api.slack.com/methods/admin.users.setExpiration\",\n",
    "# \"https://api.slack.com/methods/usergroups.users.update\",\n",
    "# \"https://api.slack.com/methods/admin.roles.listAssignments\",\n",
    "# \"https://api.slack.com/methods/admin.emoji.list\",\n",
    "# \"https://api.slack.com/methods/admin.analytics.getFile\",\n",
    "# \"https://api.slack.com/methods/admin.inviteRequests.deny\",\n",
    "# \"https://api.slack.com/methods/files.remote.share\",\n",
    "# \"https://api.slack.com/methods/apps.manifest.export\",\n",
    "# \"https://api.slack.com/methods/team.billing.info\",\n",
    "# \"https://api.slack.com/methods/oauth.v2.access\",\n",
    "# \"https://api.slack.com/methods/calls.participants.add\",\n",
    "# \"https://api.slack.com/methods/apps.activities.list\",\n",
    "# \"https://api.slack.com/methods/tooling.tokens.rotate\",\n",
    "# \"https://api.slack.com/methods/team.preferences.list\",\n",
    "# \"https://api.slack.com/methods/assistant.threads.setStatus\",\n",
    "# \"https://api.slack.com/methods/admin.apps.uninstall\",\n",
    "# \"https://api.slack.com/methods/openid.connect.userInfo\",\n",
    "# \"https://api.slack.com/methods/admin.usergroups.removeChannels\",\n",
    "# \"https://api.slack.com/methods/admin.workflows.search\",\n",
    "# \"https://api.slack.com/methods/conversations.canvases.create\",\n",
    "# \"https://api.slack.com/methods/admin.teams.list\",\n",
    "# \"https://api.slack.com/methods/canvases.access.set\",\n",
    "# \"https://api.slack.com/methods/conversations.externalInvitePermissions.set\",\n",
    "# \"https://api.slack.com/methods/chat.scheduledMessages.list\",\n",
    "# \"https://api.slack.com/methods/admin.barriers.list\",\n",
    "# \"https://api.slack.com/methods/auth.teams.list\",\n",
    "# \"https://api.slack.com/methods/apps.connections.open\",\n",
    "# \"https://api.slack.com/methods/files.comments.delete\",\n",
    "# \"https://api.slack.com/methods/team.externalTeams.list\",\n",
    "# \"https://api.slack.com/methods/users.discoverableContacts.lookup\",\n",
    "# \"https://api.slack.com/methods/users.profile.get\",\n",
    "# \"https://api.slack.com/methods/canvases.sections.lookup\",\n",
    "# \"https://api.slack.com/methods/admin.functions.list\",\n",
    "# \"https://api.slack.com/methods/admin.inviteRequests.denied.list\",\n",
    "# \"https://api.slack.com/methods/functions.distributions.permissions.list\",\n",
    "# \"https://api.slack.com/methods/admin.teams.settings.setName\",\n",
    "# \"https://api.slack.com/methods/admin.users.session.getSettings\",\n",
    "# \"https://api.slack.com/methods/admin.apps.approved.list\",\n",
    "# \"https://api.slack.com/methods/admin.conversations.restrictAccess.listGroups\",\n",
    "# \"https://api.slack.com/methods/admin.apps.config.lookup\",\n",
    "# \"https://api.slack.com/methods/admin.teams.owners.list\",\n",
    "# \"https://api.slack.com/methods/workflows.triggers.permissions.remove\",\n",
    "# \"https://api.slack.com/methods/admin.auth.policy.removeEntities\",\n",
    "# \"https://api.slack.com/methods/admin.functions.permissions.set\",\n",
    "# \"https://api.slack.com/methods/admin.users.unsupportedVersions.export\",\n",
    "# \"https://api.slack.com/methods/apps.auth.external.delete\",\n",
    "# \"https://api.slack.com/methods/admin.conversations.ekm.listOriginalConnectedChannelInfo\",\n",
    "# \"https://api.slack.com/methods/admin.workflows.collaborators.add\",\n",
    "# \"https://api.slack.com/methods/conversations.requestSharedInvite.approve/test\",\n",
    "# \"https://api.slack.com/methods/admin.apps.activities.list\",\n",
    "# \"https://api.slack.com/methods/admin.workflows.permissions.lookup\",\n",
    "# \"https://api.slack.com/methods/functions.workflows.steps.list\",\n",
    "# \"https://api.slack.com/methods/admin.apps.restricted.list\",\n",
    "# \"https://api.slack.com/methods/admin.teams.admins.list\",\n",
    "# \"https://api.slack.com/methods/apps.event.authorizations.list\",\n",
    "# \"https://api.slack.com/methods/admin.apps.requests.list\",\n",
    "# \"https://api.slack.com/methods/admin.inviteRequests.approved.list\",\n",
    "# \"https://api.slack.com/methods/functions.workflows.steps.responses.export\",\n",
    "# \"https://api.slack.com/methods/admin.audit.anomaly.allow.updateItem\",\n",
    "# \"https://api.slack.com/methods/canvases.delete\",\n",
    "# \"https://api.slack.com/methods/api.test\",\n",
    "# \"https://api.slack.com/methods/auth.revoke\",\n",
    "# \"https://api.slack.com/methods/admin.workflows.triggers.types.permissions.set\"]\n",
    "\n",
    "await scrape_url(urls, \"user_2mmXezcGmjZCf88gT2v2waCBsXv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notion - 'object': 'error', 'status': 404, 'code': 'object_not_found',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://api.notion.com/v1/users'\n",
    "\n",
    "NOTION_API_KEY = \"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\"\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {NOTION_API_KEY}',\n",
    "    'Notion-Version': '2022-06-28'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notion_client import Client\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "NOTION_API_KEY = \"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\"\n",
    "PAGE_ID = \"368c880f710a417582d411c17fc97df6\"\n",
    "\n",
    "# Initialize the Notion client\n",
    "notion = Client(auth=NOTION_API_KEY)\n",
    "\n",
    "def get_page_content(page_id) -> dict:\n",
    "    try:\n",
    "        # Fetch the page\n",
    "        page = notion.pages.retrieve(page_id)\n",
    "        \n",
    "        # Fetch the page's content (blocks)\n",
    "        blocks = notion.blocks.children.list(page_id)\n",
    "        \n",
    "        return {\n",
    "            \"page\": page,\n",
    "            \"content\": blocks[\"results\"]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching page content: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "def extract_block_text(block):\n",
    "    \"\"\"Extract plain text from a Notion block regardless of type\"\"\"\n",
    "    block_type = block[\"type\"]\n",
    "    content = block[block_type]  # Get the content based on block type (paragraph, to_do, etc.)\n",
    "    \n",
    "    # If there's no rich_text or it's empty, return empty string\n",
    "    if not content.get(\"rich_text\"):\n",
    "        return \"\"\n",
    "    \n",
    "    # Extract plain_text from the first rich_text element\n",
    "    return content[\"rich_text\"][0][\"plain_text\"]\n",
    "\n",
    "page_content = get_page_content(PAGE_ID)\n",
    "\n",
    "full_content = []\n",
    "for block in page_content['content']:\n",
    "    text = extract_block_text(block)\n",
    "    if text:  # Only add non-empty strings\n",
    "        full_content.append(text)\n",
    "\n",
    "print(\"\\n\".join(full_content))  # Print all content together\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data structure to chunk and embed\n",
    "- plain text of every block, noting it's type, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" CREATE NEW NOTION PAGE \"\"\"\n",
    "\n",
    "# url = 'https://api.notion.com/v1/blocks/9ee421b1e59f42b28e06a3089fc6f6c6/children?page_size=100'\n",
    "\n",
    "url = 'https://api.notion.com/v1/pages'\n",
    "\n",
    "NOTION_API_KEY = \"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\"\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {NOTION_API_KEY}',\n",
    "    'Notion-Version': '2022-06-28',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "data = {\n",
    "\t\"parent\": { \"page_id\": \"4af64a52b6344443b9d7d84deef0e9df\" },\n",
    "\t\"properties\": {\n",
    "\t\t\"title\": {\n",
    "      \"title\": [{ \"type\": \"text\", \"text\": { \"content\": \"A note from your pals at Notion\" } }]\n",
    "\t\t}\n",
    "\t},\n",
    "\t\"children\": [\n",
    "    {\n",
    "      \"object\": \"block\",\n",
    "      \"type\": \"paragraph\",\n",
    "      \"paragraph\": {\n",
    "        \"rich_text\": [{ \"type\": \"text\", \"text\": { \"content\": \"You made this page using the Notion API. Pretty cool, huh? We hope you enjoy building with us.\" } }]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(response.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why isn't all kb headers being returned?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.knowledge_base.kb import get_kb_headers\n",
    "\n",
    "headers = await get_kb_headers(current_user=\"user_2mmXezcGmjZCf88gT2v2waCBsXv\")\n",
    "\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from services.db import supabase_services\n",
    "\n",
    "supabase = supabase_services.supabase_client()\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv('stock_chunks_rows.csv')\n",
    "\n",
    "# Clean array-like strings\n",
    "def clean_array_data(value):\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    try:\n",
    "        # If it's already a string representation of a list\n",
    "        if isinstance(value, str):\n",
    "            if value.startswith('[') and value.endswith(']'):\n",
    "                # Remove the brackets and split by comma\n",
    "                cleaned = value.strip('[]').replace('\"', '').split(',')\n",
    "                return [item.strip() for item in cleaned]\n",
    "            return [value]\n",
    "        elif isinstance(value, list):\n",
    "            return value\n",
    "        return [str(value)]\n",
    "    except:\n",
    "        return [str(value)]\n",
    "\n",
    "# Clean the array columns\n",
    "array_columns = ['heading', 'content']  # Add any other array columns here\n",
    "for col in array_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_array_data)\n",
    "\n",
    "# Replace NaN values with None\n",
    "df = df.replace({np.nan: None})\n",
    "\n",
    "# Process in smaller batches\n",
    "batch_size = 500  # Reduced batch size for more reliable processing\n",
    "\n",
    "def insert_batch(batch_df, batch_num):\n",
    "    try:\n",
    "        records = batch_df.to_dict('records')\n",
    "        result = supabase.table('stock_chunks').insert(records).execute()\n",
    "        print(f\"Successfully inserted batch {batch_num} with {len(records)} records\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting batch {batch_num}: {str(e)}\")\n",
    "        if records:\n",
    "            print(f\"Sample record: {records[0]}\")\n",
    "\n",
    "# Process in batches\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch_df = df[i:i + batch_size]\n",
    "    insert_batch(batch_df, i // batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat.gym_shark import chat_process\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "# Gym Shark AI Shopping Assistant System Prompt\n",
    "\n",
    "You are an AI shopping assistant for Gym Shark, a popular fitness apparel and accessories brand. Your primary role is to help customers find the perfect products, answer their questions, and provide personalized recommendations. Always maintain a friendly, energetic, and supportive tone that aligns with Gym Shark's brand image of empowering athletes and fitness enthusiasts.\n",
    "\n",
    "## Key Responsibilities:\n",
    "\n",
    "1. Product Recommendations:\n",
    "   - Based on customer preferences, workout types, body types, and style choices, suggest appropriate Gym Shark products.\n",
    "   - Consider factors such as fabric, fit, color, and functionality when making recommendations.\n",
    "\n",
    "2. Size and Fit Guidance:\n",
    "   - Assist customers in finding the right size by asking about their measurements and preferences for fit (tight, loose, etc.).\n",
    "   - Provide information on how different product lines may fit differently.\n",
    "\n",
    "3. Product Information:\n",
    "   - Offer detailed information about product features, materials, care instructions, and benefits.\n",
    "   - Explain the technology behind Gym Shark's innovative fabrics and designs.\n",
    "\n",
    "4. Outfit Coordination:\n",
    "   - Help customers create complete outfits by suggesting complementary items.\n",
    "   - Recommend products that work well for specific workout types or fitness goals.\n",
    "\n",
    "5. Order and Shipping Information:\n",
    "   - Provide information on ordering processes, shipping options, and estimated delivery times.\n",
    "   - Assist with tracking orders and addressing any shipping-related concerns.\n",
    "\n",
    "6. Returns and Exchanges:\n",
    "   - Explain Gym Shark's return and exchange policies.\n",
    "   - Guide customers through the process if they need to return or exchange an item.\n",
    "\n",
    "7. Sales and Promotions:\n",
    "   - Inform customers about ongoing sales, promotions, or special offers.\n",
    "   - Suggest products that offer good value or are currently discounted.\n",
    "\n",
    "8. Workout and Fitness Advice:\n",
    "   - Offer basic workout tips and suggestions related to the products customers are interested in.\n",
    "   - Provide general fitness motivation and encouragement.\n",
    "\n",
    "9. Brand Information:\n",
    "   - Share information about Gym Shark's history, mission, and values when relevant.\n",
    "   - Highlight Gym Shark's commitment to sustainability and ethical practices.\n",
    "\n",
    "## Guidelines:\n",
    "\n",
    "- Always prioritize customer satisfaction and aim to understand their specific needs.\n",
    "- Use positive, motivating language that encourages customers in their fitness journey.\n",
    "- Be knowledgeable about fitness trends and how Gym Shark products align with them.\n",
    "- If unsure about any product details or policies, advise the customer to check the official website or contact customer service.\n",
    "- Respect customer privacy and never ask for personal information beyond what's necessary for product recommendations.\n",
    "- Be prepared to handle common customer service scenarios with patience and professionalism.\n",
    "- Stay updated on the latest Gym Shark product releases and collections.\n",
    "- Use emojis sparingly to maintain a friendly yet professional tone.\n",
    "\n",
    "Remember, your goal is to create a positive, helpful, and engaging shopping experience that reflects Gym Shark's commitment to quality, innovation, and customer satisfaction.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "await chat_process(user_message=\"hello\", system_prompt=system_prompt, user_id=\"user_2lKpUPRJD4g5IErIdhbO7rBMn3K\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat.lk_chat import lk_chat_process\n",
    "\n",
    "\n",
    "lk_chat_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Call the function to get the generator\n",
    "    async for item in lk_chat_process(message=\"hello\", agent_id=\"a93ef199-3f74-4ab0-ac62-6284526d33d0\"):\n",
    "        print(item)\n",
    "\n",
    "# For Jupyter notebook\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Set your API key\n",
    "anthropic.api_key = 'your_api_key_here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from termcolor import colored\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "import spacy\n",
    "import requests\n",
    "from supabase import create_client, Client\n",
    "from openai import OpenAI\n",
    "from tiktoken import encoding_for_model\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_SERVICE_ROLE_KEY = os.getenv(\"SUPABASE_SERVICE_ROLE_KEY\")\n",
    "SUPABASE_ANON_KEY = os.getenv(\"SUPABASE_ANON_KEY\")\n",
    "\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY)\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat.chat import similarity_search\n",
    "\n",
    "results = await similarity_search(\"Accounts payable automation?\", {'web': ['https://piqnic.com/'], 'text_files': []})\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chunking & embedding kb\n",
    "\n",
    "in post.knowledge_base endpoint. when new item is added. we process that item through the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user = \"user_2lKpUPRJD4g5IErIdhbO7rBMn3K\"\n",
    "items = supabase.table('knowledge_base').select('*').eq('user_id', current_user).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "data = items.data[1]['content']\n",
    "doc = nlp(data)\n",
    "cleaned_text = ' '.join([token.text for token in doc if not token.is_space and not token.is_punct])\n",
    "\n",
    "\n",
    "def count_tokens(text, model=\"gpt-4o\"):\n",
    "    encoder = encoding_for_model(model)\n",
    "    tokens = encoder.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "def sliding_window_chunking(text, max_window_size=600, overlap=200):\n",
    "    encoder = encoding_for_model(\"gpt-4o\")  # Use the same model as in count_tokens\n",
    "    tokens = encoder.encode(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = start + max_window_size\n",
    "        chunk_tokens = tokens[start:end]\n",
    "        chunk = encoder.decode(chunk_tokens)\n",
    "        chunks.append(chunk)\n",
    "        start += max_window_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def insert_chunk(parent_id, content, chunk_index, embedding):\n",
    "    print(\"func insert_chunk...\")\n",
    "    supabase.table('chunks').insert({\n",
    "        'parent_id': parent_id,\n",
    "        'content': content,\n",
    "        'chunk_index': chunk_index,\n",
    "        'embedding': embedding\n",
    "    }).execute()\n",
    "\n",
    "def get_embedding(text):\n",
    "    response = openai.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def process_item(item_id, content):\n",
    "    print(\"func process_item...\")\n",
    "    chunks = sliding_window_chunking(content) \n",
    "    for index, chunk in enumerate(chunks):\n",
    "        embedding = get_embedding(chunk)\n",
    "        print(\"index\", index)\n",
    "        print(\"chunk\", chunk)\n",
    "        print(\"embedding\", embedding)\n",
    "        insert_chunk(item_id, chunk, index, embedding)\n",
    "#process_item(item_id=items.data[1]['id'], content=cleaned_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerank RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_search(query, table_name, match_threshold=0.2, match_count=10):\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    response = supabase.rpc(\n",
    "        'match_documents',\n",
    "        {\n",
    "            'query_embedding': query_embedding,\n",
    "            'match_threshold': match_threshold,\n",
    "            'match_count': match_count,\n",
    "            'table_name': table_name\n",
    "        }\n",
    "    ).execute()\n",
    "    return response.data\n",
    "\n",
    "\n",
    "def rerank_documents(user_query, top_n, docs):\n",
    "    url = 'https://api.jina.ai/v1/rerank'\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': 'Bearer jina_b716ce28cd1b49bc920e57a5bfb6de061z36vM3vogg6y-_2d5qcoXHe_rdo'\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"jina-reranker-v2-base-multilingual\",\n",
    "        \"query\": user_query,\n",
    "        \"top_n\": top_n,\n",
    "        \"documents\": docs\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    reranked_docs = response.json()['results']\n",
    "    reranked_docs = [i['document']['text'] for i in reranked_docs]\n",
    "    return reranked_docs\n",
    "\n",
    "\n",
    "def rag_response(user_query):\n",
    "    table_name = \"chunks\"\n",
    "    results = similarity_search(user_query,table_name)\n",
    "    docs = [result['content'] for result in results]\n",
    "    reranked_docs = rerank_documents(user_query, 3, docs)\n",
    "\n",
    "    return reranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant designed to search the company knowledge base, and find relevant information to answer questions from users.\n",
    "\n",
    "Be conversational and friendly, and at times informal, while maintaining a dignified professional persona.\n",
    "\n",
    "Where a question from the user appears to be best answered by information from the knowledge base, you will use the <context> to augment your response to the user.\n",
    "\n",
    "Where your responses involved listing, or providing of information. Format them in markdown to allow for pretty displaying to the user to enable intuitive and quick understanding of the information you have kindly provided.\n",
    "\n",
    "\"\"\"\n",
    "conversation_history = {\n",
    "    \"user_history\": [],\n",
    "    \"assistant_history\": [],\n",
    "    \"function_history\": []\n",
    "}\n",
    "\n",
    "def llm_response(system_prompt, user_prompt, conversation_history):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    # full_response = \"\"\n",
    "    # tool_calls = []\n",
    "\n",
    "    # for chunk in response:\n",
    "    #     delta = chunk.choices[0].delta\n",
    "    #     if delta.content:\n",
    "    #         yield delta.content\n",
    "    #         full_response += delta.content\n",
    "    #     if delta.tool_calls:\n",
    "    #         tool_calls.extend(delta.tool_calls)\n",
    "\n",
    "    # conversation_history[\"user_history\"].append({\"role\": 'user', \"content\": user_prompt})\n",
    "    # conversation_history[\"assistant_history\"].append({\"role\": 'assistant', \"content\": response})\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_query = \"tell me a little about flowon\"\n",
    "retrieved_docs = rag_response(user_query)\n",
    "user_prompt = f\"\"\"{user_query}\n",
    "retrieved docs {retrieved_docs} \"\"\"\n",
    "\n",
    "response = llm_response(system_prompt, user_prompt, conversation_history)\n",
    "\n",
    "# response_received = False\n",
    "# for response_chunk in llm_response(system_prompt, user_prompt, conversation_history):\n",
    "#     response_received = True\n",
    "#     print(response_chunk, end='', flush=True)\n",
    "\n",
    "response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
