{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __ INIT __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.db.supabase_services import supabase_client\n",
    "supabase = supabase_client()\n",
    "\n",
    "from app.core.config import settings\n",
    "import requests\n",
    "import json\n",
    "from typing import Dict, Annotated, Optional, List, Union\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from services.cache import get_agent_metadata, get_all_agents\n",
    "\n",
    "from services.chat.chat import similarity_search, get_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In_mem kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Initialize an in-memory index\n",
    "dimension = 1024  \n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add vectors\n",
    "vectors = np.random.random((1000, dimension)).astype('float32')\n",
    "index.add(vectors)\n",
    "\n",
    "# Perform similarity search\n",
    "query = np.random.random((1, dimension)).astype('float32')\n",
    "k = 5  # Number of nearest neighbors\n",
    "distances, indices = index.search(query, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_user_kb(user_id: str) :\n",
    "    try:\n",
    "        # Fetch chunks for the user\n",
    "        chunks_response = supabase.table('chunks') \\\n",
    "            .select('*') \\\n",
    "            .eq('user_id', user_id) \\\n",
    "            .execute()\n",
    "\n",
    "        # Fetch web data for the user\n",
    "        web_data_response = supabase.table('user_web_data') \\\n",
    "            .select('*') \\\n",
    "            .eq('user_id', user_id) \\\n",
    "            .execute()\n",
    "\n",
    "        return {\n",
    "            'chunks': chunks_response.data,\n",
    "            'web_data': web_data_response.data\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching user data: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "user_kb: Union[Dict, None] = await get_user_kb(\"user_2mmXezcGmjZCf88gT2v2waCBsXv\")\n",
    "\n",
    "async def filter_agent_kb(data: Union[Dict, None], \n",
    "                        data_source: Dict[str, List[Union[str, int]]]):\n",
    "    data_source: Dict = json.loads(data_source)\n",
    "    data_source: Dict = {\n",
    "        \"web\": [item['title'] for item in data_source if item['data_type'] == 'web'],\n",
    "        \"text_files\": [item['id'] for item in data_source if item['data_type'] != 'web']\n",
    "    }     \n",
    "\n",
    "    if not data:\n",
    "        return {'web_data': [], 'chunks': []}\n",
    "    \n",
    "    return {\n",
    "        'web_data': [item for item in data.get('web_data', []) \n",
    "                    if item.get('root_url') in data_source.get('web', [])],\n",
    "        'chunks': [item for item in data.get('chunks', []) \n",
    "                if item.get('parent_id') in data_source.get('text_files', [])]}\n",
    "\n",
    "\n",
    "async def similarity_search_db(data_source: str, query: str):\n",
    "    if data_source != \"all\":\n",
    "        data_source: Dict = json.loads(data_source)\n",
    "        data_source: Dict = {\n",
    "            \"web\": [item['title'] for item in data_source if item['data_type'] == 'web'],\n",
    "            \"text_files\": [item['id'] for item in data_source if item['data_type'] != 'web']\n",
    "        }\n",
    "        results = await similarity_search(query, data_source=data_source, user_id=\"user_2mmXezcGmjZCf88gT2v2waCBsXv\")\n",
    "        \n",
    "        print(\"supabase results:\", results)\n",
    "    elif data_source == \"all\":\n",
    "        data_source = {\"web\": [\"all\"], \"text_files\": [\"all\"]}\n",
    "        results = await similarity_search(query, data_source=data_source, user_id=\"user_2mmXezcGmjZCf88gT2v2waCBsXv\")\n",
    "        \n",
    "        print(\"supabase results:\", results)\n",
    "        return results\n",
    "    \n",
    "\n",
    "query = \"what is the cost of an oil change\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_metadata: Dict = await get_agent_metadata(\"aaf5fce2-c925-4a32-aefc-e4af35d4b8e1\")\n",
    "data_source: str = agent_metadata.get('dataSource', None)\n",
    "\n",
    "agent_kb_data = await filter_agent_kb(data=user_kb, data_source=data_source)\n",
    "\n",
    "agent_kb_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM TEXT-TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livekit.agents import llm\n",
    "from livekit.plugins import openai  # or anthropic\n",
    "\n",
    "async def chat_with_llm():\n",
    "    # Initialize the LLM\n",
    "    llm_instance = openai.LLM()  # or anthropic.LLM()\n",
    "    \n",
    "    # Create initial chat context\n",
    "    chat_ctx = llm.ChatContext()\n",
    "    \n",
    "    # Add system message if desired\n",
    "    chat_ctx.append(\n",
    "        role=\"system\",\n",
    "        text=\"You are a helpful assistant.\"\n",
    "    )\n",
    "    \n",
    "    # Add user message\n",
    "    chat_ctx.append(\n",
    "        role=\"user\", \n",
    "        text=\"Hello, how are you?\"\n",
    "    )\n",
    "    \n",
    "    # Get response stream\n",
    "    response_stream = llm_instance.chat(chat_ctx=chat_ctx)\n",
    "    \n",
    "    # Collect the response\n",
    "    full_response = \"\"\n",
    "    async for chunk in response_stream:\n",
    "        # Each chunk.choices[0].delta.content contains a text fragment\n",
    "        if chunk.choices[0].delta.content:\n",
    "            text_fragment = chunk.choices[0].delta.content\n",
    "            full_response += text_fragment\n",
    "            print(text_fragment, end=\"\", flush=True)  # For real-time output\n",
    "    \n",
    "    #print(\"\\nFull response:\", full_response)\n",
    "\n",
    "await chat_with_llm()\n",
    "# Run with:\n",
    "# asyncio.run(chat_with_llm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livekit.agents import llm\n",
    "from livekit.plugins import openai\n",
    "from livekit.agents.llm import USE_DOCSTRING\n",
    "from services.cache import get_agent_metadata\n",
    "\n",
    "from services.chat.chat import similarity_search\n",
    "\n",
    "@llm.ai_callable(\n",
    "    name=\"search_products_and_services\",\n",
    "    description=\"Search for products and services in the database when the user inquires about specific offerings, prices, or availability\",\n",
    "    auto_retry=True\n",
    ")\n",
    "async def search_products_and_services(\n",
    "    query: Annotated[\n",
    "        str,\n",
    "        llm.TypeInfo(\n",
    "            description=\"The search query containing keywords about products or services\"\n",
    "        )\n",
    "    ],\n",
    "    category: Annotated[\n",
    "        str, \n",
    "        llm.TypeInfo(\n",
    "            description=\"The category to search in: 'products', 'services', or 'both'\"\n",
    "        )\n",
    "    ] = \"both\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Performs a semantic search in the database for products and services based on the user's query.\n",
    "    Returns formatted information about matching products/services.\n",
    "    \"\"\"\n",
    "    # try:\n",
    "    print(\"\\n=-+_=-+_=-+_ inside search_products_and_services\")\n",
    "    agent_metadata: Dict = await get_agent_metadata(\"aaf5fce2-c925-4a32-aefc-e4af35d4b8e1\")\n",
    "    data_source: str = agent_metadata.get('dataSource', None)\n",
    "\n",
    "\n",
    "\n",
    "    return f\"Found matching products/services: {results}\"\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error in search_products_and_services: {str(e)}\")\n",
    "    #     return \"Sorry, I encountered an error while searching for products and services.\"\n",
    "\n",
    " \n",
    "async def test_llm_function_calls():\n",
    "    llm_instance = openai.LLM()\n",
    "    \n",
    "    # Create function context\n",
    "    fnc_ctx = llm.FunctionContext()\n",
    "    fnc_ctx._register_ai_function(search_products_and_services)\n",
    "    \n",
    "    # Create chat context\n",
    "    chat_ctx = llm.ChatContext()\n",
    "    chat_ctx.append(\n",
    "        role=\"user\",\n",
    "        text=\"what is the cost of an oil change?\"\n",
    "    )\n",
    "    \n",
    "    # Get response stream with function context\n",
    "    response_stream = llm_instance.chat(\n",
    "        chat_ctx=chat_ctx,\n",
    "        fnc_ctx=fnc_ctx\n",
    "    )\n",
    "    \n",
    "    async for chunk in response_stream:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "        elif chunk.choices[0].delta.tool_calls:\n",
    "            # Handle function calls\n",
    "            for tool_call in chunk.choices[0].delta.tool_calls:\n",
    "                print(f\"\\nFunction called: {tool_call.function_info.name}\")\n",
    "                print(f\"Arguments: {tool_call.arguments}\")\n",
    "                \n",
    "                # Execute the function\n",
    "                called_function = tool_call.execute()\n",
    "                result = await called_function.task\n",
    "                print(f\"Function result: {result}\")\n",
    "\n",
    "await test_llm_function_calls()\n",
    "# Run with:\n",
    "# asyncio.run(test_llm_function_calls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@llm.ai_callable(\n",
    "    name=\"search_products_and_services\",\n",
    "    description=\"Search for products and services in the database when the user inquires about specific offerings, prices, or availability\",\n",
    "    auto_retry=True\n",
    ")\n",
    "async def search_products_and_services(\n",
    "    self,\n",
    "    query: Annotated[\n",
    "        str,\n",
    "        llm.TypeInfo(\n",
    "            description=\"The search query containing keywords about products or services\"\n",
    "        )\n",
    "    ],\n",
    "    category: Annotated[\n",
    "        str,  # Changed from Optional[Literal[\"products\", \"services\", \"both\"]]\n",
    "        llm.TypeInfo(\n",
    "            description=\"The category to search in: 'products', 'services', or 'both'\"\n",
    "        )\n",
    "    ] = \"both\",\n",
    "    max_results: Annotated[\n",
    "        int,  # Changed from Optional[int]\n",
    "        llm.TypeInfo(\n",
    "            description=\"Maximum number of results to return (between 1 and 10)\"\n",
    "        )\n",
    "    ] = 5\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Performs a semantic search in the database for products and services based on the user's query.\n",
    "    Returns formatted information about matching products/services.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Searching products/services with query: {query}, category: {category}\")\n",
    "    job_id = self.job_ctx.job.id\n",
    "    room_name = self.job_ctx.room.name\n",
    "    user_id = '_'.join(room_name.split('_')[3:])  # Extract user_id from room name\n",
    "    agent_id = room_name.split('_')[1]  # Extract agent_id from room name\n",
    "\n",
    "    print(\"\\n\\n\\n\\n FUNCTION CALL: search_products_and_services\")\n",
    "    print(f\"job_id: {job_id}, room_name: {room_name}, user_id: {user_id}\")\n",
    "    print(f\"Searching products/services with query: {query}, category: {category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anthropic pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import base64\n",
    "import httpx\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# First fetch the file\n",
    "pdf_url = \"https://assets.anthropic.com/m/1cd9d098ac3e6467/original/Claude-3-Model-Card-October-Addendum.pdf\"\n",
    "pdf_data = base64.standard_b64encode(httpx.get(pdf_url).content).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "# Finally send the API request\n",
    "client = anthropic.Anthropic()\n",
    "message = client.beta.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    betas=[\"pdfs-2024-09-25\"],\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"document\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"application/pdf\",\n",
    "                        \"data\": pdf_data\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Which model has the highest human preference win rates across each use-case?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat.chat import similarity_search\n",
    "\n",
    "await similarity_search(\"pre packaged admin\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.cache import get_agent_metadata\n",
    "import json \n",
    "from services.db.supabase_services import supabase_client\n",
    "supabase = supabase_client()\n",
    "\n",
    "agents_metadata = await get_agent_metadata(\"13400af9-0655-46bc-a815-9664910c2abc\")\n",
    "data_source = agents_metadata.get('dataSource', None)\n",
    "if data_source != \"all\":\n",
    "    data_source = json.loads(data_source)\n",
    "    data_source = {\n",
    "                \"web\": [item['title'] for item in data_source if item['data_type'] == 'web'],\n",
    "                \"text_files\": [item['id'] for item in data_source if item['data_type'] != 'web']\n",
    "            }\n",
    "\n",
    "elif data_source == \"all\":\n",
    "    data_source\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat.chat import get_embedding\n",
    "query_embedding = await get_embedding(\"jina embedding model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nylas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" NYLAS WEBHOOK SET UP \"\"\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from nylas import Client\n",
    "from nylas.models.webhooks import WebhookTriggers\n",
    "\n",
    "nylas = Client(\n",
    "  os.environ.get('NYLAS_API_KEY'),\n",
    "  os.environ.get('NYLAS_API_URI')\n",
    ")\n",
    "\n",
    "grant_id = \"5ef0555c-25ab-4b4e-b4a1-02fd8ba4d255\"\n",
    "webhook_url = \"https://internally-wise-spaniel.eu.ngrok.io/api/v1/nylas/webhook\"\n",
    "\n",
    "email = os.environ.get(\"EMAIL\")\n",
    "\n",
    "webhook = nylas.webhooks.create(\n",
    "  request_body={\n",
    "    \"trigger_types\": [WebhookTriggers.EVENT_CREATED],\n",
    "    \"webhook_url\": webhook_url,\n",
    "    \"description\": \"My first webhook\",\n",
    "    \"notification_email_address\": email,\n",
    "  }\n",
    ")\n",
    "\n",
    "print(webhook)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYLAS API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from nylas import Client\n",
    "from typing import List, Dict, Any\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "NYLAS_API_KEY = os.getenv(\"NYLAS_API_KEY\")\n",
    "NYLAS_API_URI = os.getenv(\"NYLAS_API_URI\")\n",
    "\n",
    "# Initialize Nylas client\n",
    "nylas = Client(\n",
    "    api_key = NYLAS_API_KEY,\n",
    "    api_uri = NYLAS_API_URI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" WORKING SEND EMAIL \"\"\"\n",
    "\n",
    "grant_id = \"5ef0555c-25ab-4b4e-b4a1-02fd8ba4d255\"\n",
    "email = \"michael@flowon.ai\"\n",
    "\n",
    "#attachment = utils.file_utils.attach_file_request_builder(\"Nylas_Logo.png\")\n",
    "\n",
    "message = nylas.messages.send(\n",
    "  grant_id,\n",
    "  request_body={\n",
    "    \"to\": [{ \"name\": \"Name\", \"email\": email }],\n",
    "    \"reply_to\": [{ \"name\": \"Name\", \"email\": email }],\n",
    "    \"subject\": \"Your Subject Here\",\n",
    "    \"body\": \"Your email body here.\",\n",
    "  }\n",
    ")\n",
    "\n",
    "print(message)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get calendar id\"\"\"\n",
    "grant_id = \"5ef0555c-25ab-4b4e-b4a1-02fd8ba4d255\"\n",
    "\n",
    "calendar = nylas.calendars.find(\n",
    "    grant_id,\n",
    "    \"primary\"\n",
    ")\n",
    "\n",
    "print(calendar)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" WORKING GET CALENDAR EVENTS \"\"\"\n",
    "calendar_id = \"AAkALgAAAAAAHYQDEapmEc2byACqAC-EWg0AT6mu_rvDikK57fYroNKSNAAEWMJ6ZAAA\"\n",
    "\n",
    "def get_calendar_events(grant_id: str, calendar_id: str = \"primary\", limit: int = 100) -> List[Dict[Any, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch calendar events for a given grant (email) from Nylas API.\n",
    "    \"\"\"\n",
    "    # Use the v3 endpoint format\n",
    "    url = f\"{NYLAS_API_URI}/v3/grants/{grant_id}/events\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {NYLAS_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        \"calendar_id\": calendar_id,\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# Test the function\n",
    "get_calendar_events(\"5ef0555c-25ab-4b4e-b4a1-02fd8ba4d255\", calendar_id=calendar_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.knowledge_base.kb import get_kb_items\n",
    "\n",
    "response = await get_kb_items(\"user_2mmXezcGmjZCf88gT2v2waCBsXv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "def group_by_root_url(items):\n",
    "    if not isinstance(items, list):\n",
    "        raise TypeError(f\"Expected a list, got {type(items)}\")\n",
    "    \n",
    "    # Sort items by root_url\n",
    "    sorted_items = sorted(items, key=itemgetter('root_url'))\n",
    "    \n",
    "    # Group items and create consolidated records\n",
    "    result = []\n",
    "    for root_url, group in groupby(sorted_items, key=itemgetter('root_url')):\n",
    "        group_list = list(group)\n",
    "        \n",
    "        # Create consolidated record\n",
    "        consolidated = {\n",
    "            'title': root_url,  # Using root_url as title\n",
    "            'root_url': root_url,\n",
    "            'content': [{  # Group of URLs and their fields\n",
    "                'url': item.get('url', ''),\n",
    "                'id': item['id'],\n",
    "                'token_count': item.get('token_count', 0)\n",
    "            } for item in group_list],\n",
    "            'created_at': next(iter(group_list)).get('created_at', ''),  # Take created_at from first item\n",
    "            'data_type': 'web',\n",
    "            'user_id': group_list[0].get('user_id')  # Assuming user_id is consistent within group\n",
    "        }\n",
    "        result.append(consolidated)\n",
    "    \n",
    "    return result\n",
    "\n",
    "grouped = group_by_root_url(response)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped[0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.chat.chat import similarity_search\n",
    "\n",
    "await similarity_search(\"what is the cost of an oil change\", table_names=[\"user_text_files\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
